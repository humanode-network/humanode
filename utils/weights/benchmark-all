#!/bin/bash
set -euo pipefail
cd "$(dirname "${BASH_SOURCE[0]}")/../.."

# Path to the humanode-peer.
BENCHMARK_HUMANODE_PEER="${BENCHMARK_HUMANODE_PEER:?A path to the humanode-peer is requied}"

# Benchmark execution result directory.
BENCHMARK_OUTPUT_DIR="${BENCHMARK_OUTPUT_DIR:-"crates/humanode-runtime/src/weights"}"

# The temporary directory to keep the intermediate benchmark renders.
BENCHMARK_OUTPUT_TEMP_DIR="${BENCHMARK_OUTPUT_TEMP_DIR:-"target/weights"}"

# The path to save the benchmarking data JSON file at.
BENCHMARK_OUTPUT_JSON_FILE="${BENCHMARK_OUTPUT_JSON_FILE:-"crates/humanode-runtime/assets/benchmark.json"}"

# The path to our custom template.
BENCHMARK_TEMPLATE_FILE="${BENCHMARK_TEMPLATE_FILE:-"utils/weights/assets/template.hbs"}"

# Skip benchmark computation.
BENCHMARK_SKIP_COMPUTE="${BENCHMARK_SKIP_COMPUTE:-}"

case "${BENCHMARK_MODE:?Specify the benchmark mode}" in
"check")
  DEFAULT_STEPS=2
  DEFAULT_REPEAT=0
  DEFAULT_EXTERNAL_REPEAT=0
  ;;
"dev")
  DEFAULT_STEPS=2
  DEFAULT_REPEAT=1
  DEFAULT_EXTERNAL_REPEAT=1
  ;;
"production")
  DEFAULT_STEPS=50
  DEFAULT_REPEAT=20
  DEFAULT_EXTERNAL_REPEAT=20
  ;;
"*")
  printf "Unknown mode: %s\n" "$BENCHMARK_MODE" >&2
  exit 1
  ;;
esac

if [[ "$BENCHMARK_HUMANODE_PEER" == "#build" ]]; then
  cargo build --release --bin humanode-peer --features runtime-benchmarks
  BENCHMARK_HUMANODE_PEER="target/release/humanode-peer"
fi

BENCH_COMMAND_BASE=(
  "$BENCHMARK_HUMANODE_PEER"
  benchmark
  pallet
)

BENCH_COMPUTE_COMMAND=(
  "${BENCH_COMMAND_BASE[@]}"
  --chain benchmark
  --pallet '*'
  --extrinsic '*'
  --output "$BENCHMARK_OUTPUT_TEMP_DIR"
  --json-file "$BENCHMARK_OUTPUT_JSON_FILE"
  --steps "${BENCHMARK_STEPS:-"$DEFAULT_STEPS"}"
  --repeat "${BENCHMARK_REPEAT:-"$DEFAULT_REPEAT"}"
  --external-repeat "${BENCHMARK_EXTERNAL_REPEAT:-"$DEFAULT_EXTERNAL_REPEAT"}"
)

BENCH_COMPUTE_COMMAND+=("$@")

BENCH_RENDER_COMMAND=(
  "${BENCH_COMMAND_BASE[@]}"
  --json-input "$BENCHMARK_OUTPUT_JSON_FILE"
  --output "$BENCHMARK_OUTPUT_DIR"
)

if [[ "$BENCHMARK_TEMPLATE_FILE" != "#built-in" ]]; then
  BENCH_RENDER_COMMAND+=(
    --template "$BENCHMARK_TEMPLATE_FILE"
  )
fi

list_mods() {
  find "$BENCHMARK_OUTPUT_DIR" \
    -mindepth 1 \
    -maxdepth 1 \
    -name '*.rs' \
    \! -name 'mod.rs' |
    sed -e 's|.*/\([^/]*\).rs$|pub mod \1;|g' |
    sort
}

printf "=> Mode: \n%s\n" "$BENCHMARK_MODE"
printf "=> Benchmark computation command: \n%s\n" "${BENCH_COMPUTE_COMMAND[*]}"
printf "=> Weight files rendering command: \n%s\n" "${BENCH_RENDER_COMMAND[*]}"
printf "=> Saving weight files to: \n%s\n" "$BENCHMARK_OUTPUT_DIR"
printf "=> Saving JSON file to: \n%s\n" "$BENCHMARK_OUTPUT_JSON_FILE"

printf "=> Benchmark computation:\n"
if [[ "$BENCHMARK_SKIP_COMPUTE" == "true" ]]; then
  printf "Skipped..."
else
  mkdir -p \
    "$(dirname "$BENCHMARK_OUTPUT_JSON_FILE")" \
    "$BENCHMARK_OUTPUT_TEMP_DIR"

  "${BENCH_COMPUTE_COMMAND[@]}"
fi

if [[ "$BENCHMARK_MODE" == "check" ]]; then
  printf "Skipping weight files rendering in check mode..." >&2
  exit 0
fi

printf "=> Weight files rendering:\n"
rm -rf "$BENCHMARK_OUTPUT_DIR"
mkdir -p "$BENCHMARK_OUTPUT_DIR"
"${BENCH_RENDER_COMMAND[@]}"

MODS_LIST="$(list_mods)"

cat <<EOF >"${BENCHMARK_OUTPUT_DIR}/mod.rs"
// DO NOT EDIT! This file is generated by "${BASH_SOURCE[0]}" command.
//! Computed benchmarks.
//! Mode: "$BENCHMARK_MODE"

${MODS_LIST}
EOF
