#!/bin/bash
set -euo pipefail
cd "$(dirname "${BASH_SOURCE[0]}")/../.."

# Path to the humanode-peer.
BENCHMARK_HUMANODE_PEER="${BENCHMARK_HUMANODE_PEER:?A path to the humanode-peer is requied}"

# Benchmark execution result directory.
BENCHMARK_OUTPUT_DIR="${BENCHMARK_OUTPUT_DIR:-"crates/humanode-runtime/src/weights"}"

# The path to our custom template.
BENCHMARK_TEMPLATE_FILE="${BENCHMARK_TEMPLATE_FILE:-"utils/weights/assets/template.hbs"}"

case "${BENCHMARK_MODE:?Specify the benchmark mode}" in
"check")
  DEFAULT_STEPS=2
  DEFAULT_REPEAT=0
  DEFAULT_EXTERNAL_REPEAT=0
  ;;
"dev")
  DEFAULT_STEPS=2
  DEFAULT_REPEAT=1
  DEFAULT_EXTERNAL_REPEAT=1
  ;;
"production")
  DEFAULT_STEPS=50
  DEFAULT_REPEAT=20
  DEFAULT_EXTERNAL_REPEAT=20
  ;;
"*")
  printf "Unknown mode: %s\n" "$BENCHMARK_MODE" >&2
  exit 1
  ;;
esac

if [[ "$BENCHMARK_HUMANODE_PEER" == "#build" ]]; then
  cargo build --release --bin humanode-peer --features runtime-benchmarks
  BENCHMARK_HUMANODE_PEER="target/release/humanode-peer"
fi

# Base benchmark execution command.
BENCH_COMMAND=(
  "$BENCHMARK_HUMANODE_PEER"
  benchmark
  pallet
  --chain benchmark
  --pallet '*'
  --extrinsic '*'
  --output "$BENCHMARK_OUTPUT_DIR"
  --json-file "$BENCHMARK_OUTPUT_DIR/benchmark.json"
  --steps "${BENCHMARK_STEPS:-"$DEFAULT_STEPS"}"
  --repeat "${BENCHMARK_REPEAT:-"$DEFAULT_REPEAT"}"
  --external-repeat "${BENCHMARK_EXTERNAL_REPEAT:-"$DEFAULT_EXTERNAL_REPEAT"}"
)

if [[ "$BENCHMARK_TEMPLATE_FILE" != "#built-in" ]]; then
  BENCH_COMMAND+=(
    --template "$BENCHMARK_TEMPLATE_FILE"
  )
fi

BENCH_COMMAND+=("$@")

list_mods() {
  find "$BENCHMARK_OUTPUT_DIR" \
    -mindepth 1 \
    -maxdepth 1 \
    -name '*.rs' \
    \! -name 'mod.rs' |
    sed -e 's|.*/\([^/]*\).rs$|pub mod \1;|g' |
    sort
}

printf "=> Mode: \n%s\n" "$BENCHMARK_MODE"
printf "=> Full benchmark command: \n%s\n" "${BENCH_COMMAND[*]}"
printf "=> Saving output to: \n%s\n" "$BENCHMARK_OUTPUT_DIR"

if [[ "$BENCHMARK_MODE" != "check" ]]; then
  # Delete the previous results directory if it exists.
  rm -rf "$BENCHMARK_OUTPUT_DIR"
  # Create the results directory.
  mkdir -p "$BENCHMARK_OUTPUT_DIR"
fi

printf "=> Benchmark execution:\n"
"${BENCH_COMMAND[@]}"

if [[ "$BENCHMARK_MODE" == "check" ]]; then
  printf "Skipping rewriting mod.rs in check mode..." >&2
  exit 0
fi

MODS_LIST="$(list_mods)"

cat <<EOF >"${BENCHMARK_OUTPUT_DIR}/mod.rs"
// DO NOT EDIT! This file is generated by "${BASH_SOURCE[0]}" command.
//! Computed benchmarks.
//! Mode: "$BENCHMARK_MODE"

${MODS_LIST}
EOF
